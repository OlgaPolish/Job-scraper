# Инструкция по использованию модуля LinkedInJobScraper

## Описание
Этот модуль предназначен для скрапинга вакансий с платформы LinkedIn, анализа данных с использованием AI-логики и сохранения результатов в удобных форматах (Excel и CSV). Модуль реализован в виде веб-приложения на Flask.

---

## Установка и настройка

### 1. Установка зависимостей
Для работы модуля необходимо установить Python и необходимые библиотеки. Убедитесь, что у вас установлен Python версии 3.7 или выше.

Установите зависимости, перечисленные в файле `app.py`, с помощью команды:

```bash
pip install requests beautifulsoup4 pandas flask
```

### 2. Подготовка папки `templates`
Модуль автоматически создаёт папку `templates` и файл `index.html`, если они отсутствуют. Если у вас есть кастомный файл `index.html`, поместите его в корневую директорию перед запуском приложения.

---

## Запуск приложения

### 1. Запуск локального сервера
Для запуска приложения выполните команду:

```bash
python app.py
```

Приложение будет запущено на локальном сервере (по умолчанию на `http://127.0.0.1:5000`).

---

## Использование

### 1. Открытие веб-интерфейса
Перейдите в браузер и откройте адрес:
```
http://127.0.0.1:5000
```

### 2. Ввод данных для поиска вакансий
На странице приложения заполните следующие поля:
- **Keywords**: ключевые слова для поиска (например, `Data Scientist, Python Developer`).
- **Locations**: города или регионы для поиска (например, `Berlin, Munich`).
- **Max Pages**: максимальное количество страниц для скрапинга (по умолчанию 3).
- **User Prompt**: описание ваших требований к вакансиям (например, `удалённая работа, высокая зарплата`).
- **Priority Keywords**: ключевые слова для приоритизации (например, `Python, Machine Learning`).

Нажмите кнопку "Scrape" для начала обработки.

### 3. Процесс скрапинга
Модуль выполняет следующие шаги:
1. **Скрапинг вакансий**: собирает данные о вакансиях с LinkedIn.
2. **Извлечение описаний**: загружает полные описания вакансий.
3. **AI-анализ**: анализирует собранные данные, используя приоритетные ключевые слова и пользовательский запрос.
4. **Сохранение результатов**: сохраняет результаты в файлы Excel и CSV.

### 4. Получение результата
После завершения обработки на странице появится сообщение с путями к сохранённым файлам, например:
```
✅ Результаты сохранены в linkedin_jobs_ai_analysis_20250717_211200.xlsx и linkedin_jobs_ai_analysis_20250717_211200.csv.
```

---

## Структура результатов

### Формат данных
Файлы Excel и CSV содержат следующие колонки:
- **Priority**: уровень приоритета (1 — высокий, 2 — средний, 3 — низкий).
- **Title**: название вакансии.
- **Company**: компания.
- **Location**: местоположение.
- **Brief_Description**: краткое описание вакансии.
- **Skills_Match**: соответствие навыков.
- **Salary**: зарплата.
- **Remote_Work**: возможность удалённой работы.
- **Seniority_Level**: уровень позиции (Junior, Senior и др.).
- **Language**: язык вакансии (English, German, Mixed).
- **Date_Posted**: дата публикации вакансии.
- **Link**: ссылка на вакансию.
- **Description**: полное описание вакансии.

---

## Возможные ошибки и их решение

### 1. Ошибка скрапинга
Сообщение: `❌ Ошибка при скрапинге: ...`
- Решение: Убедитесь, что у вас есть доступ к LinkedIn. Попробуйте повторить запрос позже.

### 2. Ошибка получения описания
Сообщение: `❌ Ошибка получения описания: ...`
- Решение: Некоторые вакансии могут быть недоступны. Это нормально для LinkedIn.

### 3. Нет результатов
Сообщение: `❌ Вакансии не найдены.`
- Решение: Проверьте корректность введённых ключевых слов и локаций.

---

## Дополнительная информация

### Расширение функционала
Вы можете изменить параметры скрапинга, такие как количество страниц (`max_pages`) или регулярные выражения для поиска зарплаты, в классе `LinkedInJobScraper`.

### Логирование
Все этапы работы модуля логируются в консоли, чтобы вы могли отслеживать процесс.

---

Теперь модуль готов к использованию!
